{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPPOVFL/SChqoO4TK+P99R8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Get ingo about GPU"],"metadata":{"id":"Nq8pos-IGPTT"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MozytvGNC-a_","executionInfo":{"status":"ok","timestamp":1662741407857,"user_tz":-120,"elapsed":259,"user":{"displayName":"Viktoriia Sergeeva","userId":"02291745702658689990"}},"outputId":"f54596f8-c2f3-4e3d-8949-28caef7726f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Sep  9 16:36:47 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    26W /  70W |    610MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZnyMhFXDUAf","executionInfo":{"status":"ok","timestamp":1662741408334,"user_tz":-120,"elapsed":7,"user":{"displayName":"Viktoriia Sergeeva","userId":"02291745702658689990"}},"outputId":"299fa312-100b-4bdc-bc98-5256bd2a009d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","source":["# Import usefull packages"],"metadata":{"id":"50YQOtBYGVl0"}},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","import torchaudio\n","import torch\n","\n","from google.colab import drive\n","\n","from random import shuffle\n","import numpy as np\n","\n","from torch.functional import Tensor\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.optim as optim\n","\n","import matplotlib.pyplot as plt"],"metadata":{"id":"leQbgdE2DT9G","executionInfo":{"status":"ok","timestamp":1662741408334,"user_tz":-120,"elapsed":5,"user":{"displayName":"Viktoriia Sergeeva","userId":"02291745702658689990"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Check an accessibility of the GPU"],"metadata":{"id":"swVtTJC_GfLg"}},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dccEBQUSDT6f","executionInfo":{"status":"ok","timestamp":1662741408335,"user_tz":-120,"elapsed":6,"user":{"displayName":"Viktoriia Sergeeva","userId":"02291745702658689990"}},"outputId":"5db72a28-a973-46d7-954f-5a43ddd8fccd"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","source":["# Loading data"],"metadata":{"id":"eS3JnfXqGxog"}},{"cell_type":"code","source":["eps = 1e-4\n","SAMPLE_RATE = 16000\n","nFFt = 512\n","winLength = 512\n","hopLength = 256\n","nMels = 64\n","\n","\n","def normalize(data):\n","  mean, std, var = torch.mean(data), torch.std(data), torch.var(data)\n","  data = (data-mean)/std\n","  return data\n","\n","\n","class UploadArtificialDataset(Dataset):\n","    def __init__(self, file_with_paths, file_with_references, transformation, target_sample_rate, device):\n","        self.paths = self.loader(file_with_paths)\n","        self.references = self.loader(file_with_references)\n","        self.device = device\n","        self.transformation = transformation.to(self.device)\n","        self.transformation = transformation\n","        self.target_sample_rate = target_sample_rate\n","      \n","    \n","    def loader(self, path):\n","        paths = []\n","        with open(path, \"r\") as file:\n","            for line in file:\n","                paths.append(line[0:len(line)-1])\n","        return paths\n","\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","\n","    def __getitem__(self, index):\n","        # sr - sample rate\n","        signal, sr = torchaudio.load(\"/content/drive/My Drive/artificial\" + self.paths[index])\n","        signal = signal.to(self.device)\n","\n","        signal = normalize(signal)\n","        signal = self.transformation(signal)\n","        signal = signal + eps\n","        signal = 10*torch.log10(signal)\n","        \n","        references = self.references[index]\n","        ref = []\n","        ref = references.split(\"|\")\n","        return signal, ref\n","\n","\n","if __name__ == \"__main__\":\n","    paths_file = \"/content/drive/My Drive/artificial/pathsToTrainSounds.txt\"\n","    references = \"/content/drive/My Drive/artificial/trainRef.txt\"\n","\n","    spectrogram = torchaudio.transforms.MelSpectrogram(\n","        sample_rate=SAMPLE_RATE,\n","        n_fft=nFFt,\n","        win_length = winLength,\n","        hop_length = hopLength,\n","        n_mels = nMels,\n","        power=1,\n","        normalized=True\n","    )\n","    \n","    uad = UploadArtificialDataset(paths_file, references, spectrogram, SAMPLE_RATE, device)\n","\n","    print(f\"There are {len(uad)} samples in the dataset.\")\n","    signal, ref = uad[34000]\n","    print(signal.shape)\n","    print(ref)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PdUYkqhDT2C","executionInfo":{"status":"ok","timestamp":1662741412358,"user_tz":-120,"elapsed":4028,"user":{"displayName":"Viktoriia Sergeeva","userId":"02291745702658689990"}},"outputId":"81f785b9-5037-44a9-be1d-f609098c5f0c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 150684 samples in the dataset.\n","torch.Size([1, 64, 126])\n","['19.4', '20.6']\n"]}]},{"cell_type":"markdown","source":["# Irreplaceable functions\n","\n","❗ **DON'T FORGET TO UNCOMMENT SHUFFLE** ❗\n"],"metadata":{"id":"-QxgNg7AHMRb"}},{"cell_type":"code","source":["# Mix data function\n","\n","def mix_data(uad):\n","  indexes = []\n","  indexes.extend(range(0, len(uad) - 1))\n","  # shuffle(indexes)\n","  return indexes"],"metadata":{"id":"sw1sMoJ0DTs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate TEST chunk function\n","\n","def generate_chunk(ind, uad):\n","  chunk = []\n","  references = []\n","  minibatch = torch.zeros(100, nMels, int(16000 / hopLength))\n","  signal, refer = uad[ind]\n","  for i in range(100):\n","    minibatch[i] = signal[:, 0:nMels, 0:int(16000 / hopLength)]\n","    references.append(refer[0])\n","  chunk.append(minibatch)\n","  return chunk, references\n","\n","\n","s, k = generate_chunk(2, uad)\n","print(s, k)\n","print(len(k))"],"metadata":{"id":"cLRRbRAsDTmZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Definition of the network "],"metadata":{"id":"-OIM2s_MHoMP"}},{"cell_type":"code","source":["class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 8, 5)\n","        self.pool = nn.MaxPool2d(2,2)\n","        self.conv2 = nn.Conv2d(8, 16, 5)\n","        self.pool = nn.MaxPool2d(2,2)\n","        self.conv3 = nn.Conv2d(16, 32, 5)\n","        self.pool = nn.MaxPool2d(2,2)\n","        self.fc1 = nn.Linear(512, 256)\n","        self.fc2 = nn.Linear(256, 1)\n","        # 1 -> 6\n","    def forward(self, x):\n","        x = self.pool(F.elu(self.conv1(x)))\n","        # print('1. vrstva',x.shape)\n","        x = self.pool(F.elu(self.conv2(x)))\n","        # print('2. vrstva',x.shape)\n","        x = self.pool(F.elu(self.conv3(x)))\n","        # print('3. vrstva',x.shape)\n","        # x = self.pool(F.elu(self.conv4(x)))\n","        # print('4. vrstva',x.shape)\n","        # x = torch.flatten(x, 1) # flatten all \n","        x = x.view(x.size(0), -1)\n","        # print('po flatten', x.shape)\n","        x = torch.sigmoid(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"MWvUqNMkDTcf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = Net()"],"metadata":{"id":"V0kqV6JcFF6o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# If we want to train the network from the beginning, we must also run next code cell"],"metadata":{"id":"X03Q4Wq7FYAL"}},{"cell_type":"code","source":["# Creation of indexes\n","indexes = mix_data(uad)\n","indexes = np.reshape(indexes, (173, -1))\n","indexes = torch.Tensor(indexes).int()\n","\n","# Saving of created indexes\n","torch.save(indexes, '/content/drive/My Drive/artificial/indexes.pt')\n","\n","# Saving of zero number of chunk\n","number = 0\n","torch.save(number, '/content/drive/My Drive/artificial/numberOfChunk.pt')\n","\n","# Saving a base modes\n","torch.save(net.state_dict(), \"/content/drive/My Drive/artificial/modelka.pth\")"],"metadata":{"id":"D_3ylka8FF4R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Next part of the code is always run, regardless of the type of network training"],"metadata":{"id":"oESflI0FFgJg"}},{"cell_type":"code","source":["# Loading a model\n","net.load_state_dict(torch.load(\"/content/drive/My Drive/artificial/modelka.pth\"))\n","net.eval()\n","\n","# Loading indexes\n","indexes = torch.load('/content/drive/My Drive/artificial/indexes.pt')\n","\n","# Loading a number og chunk\n","number = torch.load('/content/drive/My Drive/artificial/numberOfChunk.pt')"],"metadata":{"id":"yB73SUAUFF1s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definition of a Loss function and optimizer\n","loss_epoch = nn.MSELoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"],"metadata":{"id":"KYnd2RAjFFyz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print model's state_dict\n","print(\"Model's state_dict:\")\n","for param_tensor in net.state_dict():\n","    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n","\n","# Print optimizer's state_dict\n","print(\"Optimizer's state_dict:\")\n","for var_name in optimizer.state_dict():\n","    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"],"metadata":{"id":"5Ax0HqQyFFu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sent network to the device\n","net.to(device)"],"metadata":{"id":"p8IdYKFhFFp8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training og the network"],"metadata":{"id":"sqSLhSyFGF5S"}},{"cell_type":"code","source":["# number = 0\n","indexes = [[0,0,0,0,0,0,0,0,0]]\n","# print(indexes)\n","# start = torch.cuda.Event(enable_timing=True)\n","# end = torch.cuda.Event(enable_timing=True)\n","\n","# start.record()\n","\n","patien = 0\n","patien_flag = 0\n","\n","if device.__eq__('cuda:0'):\n","  for epoch in range(500):  # loop over the dataset multiple times\n","    number = torch.load('/content/drive/My Drive/artificial/numberOfChunk.pt')\n","    for k in range(number, len(indexes)):\n","      torch.save(k, '/content/drive/My Drive/artificial/numberOfChunk.pt')\n","      chunk, reference = generate_chunk(indexes[0][1], uad)\n","      torch.save(reference, '/content/drive/My Drive/artificial/lastChunkRefer.pt')\n","      running_loss = 0.0\n","      for i in range(0, len(chunk)):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = chunk[i], reference\n","        # to float ref\n","        labels = list(map(float, labels))\n","        # to tensor ref\n","        torch.save(labels, '/content/drive/My Drive/artificial/lastLabels.pt')\n","        labels = torch.FloatTensor(labels)\n","        # labels = hot(labels)\n","        # labels = labels.type(torch.LongTensor)\n","        labels = labels.to(device)\n","        # add new dimension\n","        inputs = inputs[None,:,:,:]\n","        inputs = torch.permute(inputs, (1,0,2,3))\n","        inputs = inputs.to(device)\n","        # print(inputs.dtype)\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = loss_epoch(outputs, labels)\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(net.parameters(), 5)\n","        optimizer.step()\n","        running_loss += loss.item()\n","      print(f'[{epoch + 1}, {len(chunk)}] loss: {running_loss / len(chunk)}')\n","      if patien_flag < (running_loss/len(chunk)):\n","        patien = patien + 1\n","      patien_flag = running_loss / len(chunk)\n","      if patien == 5:\n","        break\n","    if patien == 5:\n","      break\n","      \n","    k = 0\n","    torch.save(k, '/content/drive/My Drive/artificial/numberOfChunk.pt')\n","    torch.save(net.state_dict(), \"/content/drive/My Drive/artificial/modelka.pth\")\n","  print('Finished Training')\n","else:\n","  print('Traning wasnt started, due to unavailabile cuda device')\n","\n","# end.record()"],"metadata":{"id":"uXH7hjwNF-2S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Upload development data"],"metadata":{"id":"OlGuC_-PI3o3"}},{"cell_type":"code","source":["paths_file = \"/content/drive/My Drive/artificial/pathsToDevelopSounds.txt\"\n","references = \"/content/drive/My Drive/artificial/developRef.txt\"\n","\n","spectrogram = torchaudio.transforms.MelSpectrogram(\n","    sample_rate=SAMPLE_RATE,\n","    n_fft=nFFt,\n","    win_length = winLength,\n","    hop_length = hopLength,\n","    n_mels = nMels,\n","    power=1,\n","    normalized=True\n",")\n","\n","develop_uad = UploadArtificialDataset(paths_file, references, spectrogram, SAMPLE_RATE, device)\n","\n","print(f\"There are {len(develop_uad)} samples in the dataset.\")\n","signal, ref = develop_uad[7924]\n","print(signal.shape)\n","print(ref)"],"metadata":{"id":"3EE-2lzdF-y6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prepare&Predict functions"],"metadata":{"id":"7rYMzL4zJUD4"}},{"cell_type":"code","source":["# preparation function\n","def prepare_data(signal):\n","  len = int(signal.shape[2]/int(16000 / hopLength))\n","  prepared = torch.zeros(len, nMels, int(16000 / hopLength))\n","  move = 0\n","  for k in range(len):\n","    prepared[k] = signal[:, 0:nMels, 0+move:int(16000 / hopLength)+move]\n","    move = move + int(16000 / hopLength)\n","  prepared = prepared[None,:,:,:]\n","  prepared = torch.permute(prepared, (1,0,2,3))\n","  return prepared\n","\n","\n","# prediction function\n","def predict(model, input, target):\n","    model.eval()\n","    with torch.no_grad():\n","        prediction = model(input)\n","    return prediction"],"metadata":{"id":"kRtAZpvWF-wU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing of trained network\n","\n","❗️**NEED TO BE MODIFIED**❗️"],"metadata":{"id":"Kz056NH2J1iu"}},{"cell_type":"code","source":["def do_prediction(ind):\n","  s, r = develop_uad[ind]\n","  s = prepare_data(s)\n","  s = s.to(device)\n","\n","  r = list(map(float, r))\n","  r = torch.FloatTensor(r)\n","  print(r)\n","  r = r.to(device)\n","\n","  return predict(net, s, r)\n","\n","development_indexes = indexes[0]\n","for i in development_indexes[0:50]:\n","  print('-------------', i, '-------------')\n","  prediction = do_prediction(i).tolist()\n","  prediction = np.reshape(prediction, (1, -1))[0]\n","  prediction = torch.Tensor(prediction)\n","  print(prediction)"],"metadata":{"id":"s3l2ihR2F-tc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GitHub access "],"metadata":{"id":"TDES3OXXNGHH"}},{"cell_type":"code","source":["drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/artificial/\n","# Create NEW EMPTY folder\n","# !git init vik_prj\n","%cd vik_prj/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uuh8Pio6NF1F","executionInfo":{"status":"ok","timestamp":1662743321407,"user_tz":-120,"elapsed":2582,"user":{"displayName":"Viktoriia Sergeeva","userId":"02291745702658689990"}},"outputId":"c226a44d-29de-4fe0-e8bf-67ed20453a23"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/artificial\n","/content/drive/MyDrive/artificial/vik_prj\n"]}]},{"cell_type":"code","source":["%ls -a .git/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYEaOB3qODWz","executionInfo":{"status":"ok","timestamp":1662743328446,"user_tz":-120,"elapsed":238,"user":{"displayName":"Viktoriia Sergeeva","userId":"02291745702658689990"}},"outputId":"38e848a7-e945-4b08-dd23-8f7ec5c70c12"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mbranches\u001b[0m/  config  description  HEAD  \u001b[01;34mhooks\u001b[0m/  \u001b[01;34minfo\u001b[0m/  \u001b[01;34mobjects\u001b[0m/  \u001b[01;34mrefs\u001b[0m/\n"]}]},{"cell_type":"code","source":["!git status"],"metadata":{"id":"2NSp2Nn8OAUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"GNkwm33FOiXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"Beautifully structured code cells\""],"metadata":{"id":"JQJoLgWgOi5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"viktoriia.sergeeva@tul.cz\"\n","!git config --global user.name \"ViktoriiaSr\""],"metadata":{"id":"JfvvERK8Ma9y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["username = \"ViktoriiaSr\"\n","repository = \"vir_prj\"\n","git_token = \"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\""],"metadata":{"id":"MX_bRzJzOyhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git remote add origin https://{git_token}@github.com/{username}/{repository}.git\n","!git remote -v"],"metadata":{"id":"np5nHSWTO0IF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push -u origin master"],"metadata":{"id":"oeOno8H4O5_V"},"execution_count":null,"outputs":[]}]}